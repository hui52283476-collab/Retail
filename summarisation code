from transformers import pipeline
import warnings
warnings.filterwarnings('ignore')  # Suppress model loading warnings

def summarize_text(text):
    """
    Summarizes text using a local AI model
    Args:
        text (str): Input text to summarize
    Returns:
        str: Generated summary
    """
    # Initialize summarizer (will download model ~1.5GB first time)
    summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")
    
    # Chunk long text to avoid model limitations
    max_chunk = 1024
    text_chunks = [text[i:i+max_chunk] for i in range(0, len(text), max_chunk)]
    
    summaries = []
    for chunk in text_chunks:
        summary = summarizer(chunk, 
                            max_length=150, 
                            min_length=30, 
                            do_sample=False)[0]['summary_text']
        summaries.append(summary)
    
    return " ".join(summaries)

def main():
    print("ğŸ“ Local Text Summarizer (100% offline after setup)")
    input_text = input("Enter text to summarize:\n> ")
    
    if not input_text.strip():
        print("âŒ No text entered!")
        return
    
    print("\nâš¡ Generating summary (may take 1 minute first time)...")
    summary = summarize_text(input_text)
    print("\nğŸ“– Summary:")
    print(summary)

if __name__ == "__main__":
    main()

